{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/KOSA_ChatGPT_0531/blob/main/LangChain-txt-QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 여러 문서에서 찾아서 답변하는 챗봇 만들기\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- QA ChatBot\n",
        "- LangChain\n",
        "- ChatGPT (gpt-3.5-turbo)\n",
        "- ChromaDB\n",
        "\n",
        "> Reference: https://youtu.be/3yPBVii7Ct0"
      ],
      "metadata": {
        "id": "LAG2G551Vx4T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 문서\n",
        "\n",
        "> TechCrunch 기사 21개"
      ],
      "metadata": {
        "id": "XJTc_m1GWTfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/kairess/toy-datasets/raw/master/techcrunch-articles.zip\n",
        "!unzip -q techcrunch-articles.zip -d articles"
      ],
      "metadata": {
        "id": "l6XPLPVrqEaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LangChain\n",
        "\n",
        "OpenAI API Key\n",
        "\n",
        "https://platform.openai.com/account/api-keys"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load multiple and process documents"
      ],
      "metadata": {
        "id": "9UcQKUId3X2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('./articles', glob=\"*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "PRSeXXc_3Ypj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split texts"
      ],
      "metadata": {
        "id": "L39nElP4Wdu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "id": "3__nT0D4Fkmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2:4]"
      ],
      "metadata": {
        "id": "Bg6-9jwU4ja_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Chroma DB\n",
        "\n",
        "1. Text -> Embbedings\n",
        "2. `db` 폴더에 데이터 저장\n",
        "3. DB 초기화\n",
        "4. `db` 폴더로부터 DB 로드"
      ],
      "metadata": {
        "id": "YsYsIy8F4cdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'db'\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "Q_eTIZwf4Dk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()\n",
        "vectordb = None"
      ],
      "metadata": {
        "id": "uRfD_Te-47lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding)"
      ],
      "metadata": {
        "id": "A-h1y_eAHmD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a retriever"
      ],
      "metadata": {
        "id": "siLXR-XT0JoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "6ObunFU30Lxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "for doc in docs:\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "cYA-H59u0Skn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결과를 k개 반환"
      ],
      "metadata": {
        "id": "h3mZszDFW5aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "for doc in docs:\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "58fAAOHfVLeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a chain"
      ],
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True)"
      ],
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query"
      ],
      "metadata": {
        "id": "RjyrGZyeW_iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much money did Pando raise?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "wKfX4vX-5RFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response"
      ],
      "metadata": {
        "id": "olRm73t3rNt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "wg-e6fh6rNwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did Databricks acquire?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "cuFf8D-rrN0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Generative AI?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "t5KETxphrN3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "692pHNkFrN5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "978QWCeJSRdu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}