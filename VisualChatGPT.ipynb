{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/KOSA_ChatGPT_0531/blob/main/VisualChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download visual-chatgpt\n"
      ],
      "metadata": {
        "id": "yBlt2jfzmE3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf TaskMatrix && git clone https://github.com/microsoft/TaskMatrix"
      ],
      "metadata": {
        "id": "Q4YQZaD3xI6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go to directory\n"
      ],
      "metadata": {
        "id": "AWVD0IoQX0Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd TaskMatrix/"
      ],
      "metadata": {
        "id": "RAOzak8IXwXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages\n"
      ],
      "metadata": {
        "id": "kC9nZrM-61c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install git+https://github.com/IDEA-Research/GroundingDINO.git\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git"
      ],
      "metadata": {
        "id": "Blq5fIEizcnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set your OPENAI_API_KEY\n"
      ],
      "metadata": {
        "id": "j4QdrPN-9Jyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env OPENAI_API_KEY="
      ],
      "metadata": {
        "id": "_F_Qv_qj5wd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "ZuwRTOtqYYvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from visual_chatgpt import *"
      ],
      "metadata": {
        "id": "5Q3IQ37_BrBx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run VisualChatGPT"
      ],
      "metadata": {
        "id": "XRMUM7h47H6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoints\n",
        "# load = \"ImageCaptioning_cuda:0,Text2Image_cuda:0\"\n",
        "load = \"Text2Box_cuda:0,Segmenting_cuda:0,Inpainting_cuda:0,ImageCaptioning_cuda:0\"\n",
        "\n",
        "load_dict = {e.split('_')[0].strip(): e.split('_')[1].strip() for e in load.split(',')}\n",
        "bot = ConversationBot(load_dict=load_dict)\n",
        "with gr.Blocks(css=\"#chatbot .overflow-y-auto{height:500px}\") as demo:\n",
        "    lang = gr.Radio(choices = ['Chinese','English'], value=None, label='Language')\n",
        "    chatbot = gr.Chatbot(elem_id=\"chatbot\", label=\"Visual ChatGPT\")\n",
        "    state = gr.State([])\n",
        "    with gr.Row(visible=False) as input_raws:\n",
        "        with gr.Column(scale=0.7):\n",
        "            txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter, or upload an image\").style(\n",
        "                container=False)\n",
        "        with gr.Column(scale=0.15, min_width=0):\n",
        "            clear = gr.Button(\"ClearÔ∏è\")\n",
        "        with gr.Column(scale=0.15, min_width=0):\n",
        "            btn = gr.UploadButton(\"üñºÔ∏è\", file_types=[\"image\"])\n",
        "    lang.change(bot.init_agent, [lang], [input_raws, lang, txt, clear])\n",
        "    txt.submit(bot.run_text, [txt, state], [chatbot, state])\n",
        "    txt.submit(lambda: \"\", None, txt)\n",
        "    btn.upload(bot.run_image, [btn, state, txt, lang], [chatbot, state, txt])\n",
        "    clear.click(bot.memory.clear)\n",
        "    clear.click(lambda: [], None, chatbot)\n",
        "    clear.click(lambda: [], None, state)\n",
        "    demo.launch(server_name=\"0.0.0.0\", server_port=7860, share=True, debug=True)"
      ],
      "metadata": {
        "id": "8nCGkaV0_xBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Human: provide a figure named image/a666d3e1.png. The description is: [**a woman in white shorts and a green top.**][ÎßÅÌÅ¨ ÌÖçÏä§Ìä∏](https://drive.google.com/file/d/1EZGu6FGu3xYTBjc5V-aCBjD-rmqK2STl/view?usp=share_link) This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
        "AI: Received.  \n",
        "\n",
        "\n",
        "Human: provide a figure named image/cbb015e9.png. The description is: [**a barcode label on a bottle of beer.**][ÎßÅÌÅ¨ ÌÖçÏä§Ìä∏](https://drive.google.com/file/d/12atEOre8xchZtV69fkWJJznIkIM2WTPg/view?usp=share_link) This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
        "AI: Received.  \n",
        "\n",
        "\n",
        "Human: provide a figure named image/4d25fe30.png. The description is: [**a large elephant walking across a field.**] [ÎßÅÌÅ¨ ÌÖçÏä§Ìä∏](https://drive.google.com/file/d/1IcBrgcx8NP85gYg5XrhPhr12GgGDPweu/view?usp=share_link)This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
        "AI: Received.  \n",
        "\n",
        "\n",
        "Human: provide a figure named image/bf3a7ddd.png. The description is: [**a boat docked at the dock in the water.**] [ÎßÅÌÅ¨ ÌÖçÏä§Ìä∏](https://drive.google.com/file/d/1ao_3LilurZH00pbZoDXZSn3nX2Hc3kmH/view?usp=share_link)This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
        "AI: Received.  \n",
        "\n",
        "\n",
        "Human: provide a figure named image/7a967518.png. The description is: [**a gifet is looking over a fence.**] [ÎßÅÌÅ¨ ÌÖçÏä§Ìä∏](https://drive.google.com/file/d/1nSWbWKOA-NN0otRR_-8rgFKUw-hZuuP1/view?usp=share_link) This information helps you to understand this image, but you should use tools to finish following tasks, rather than directly imagine from my description. If you understand, say \"Received\". \n",
        "AI: Received."
      ],
      "metadata": {
        "id": "u2IFjYVdcbwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PsMjSaqicVr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -aux | grep \"python\"\n",
        "# !kill -9 7507    "
      ],
      "metadata": {
        "id": "pfsB6JV39qQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48c777d-2038-4471-c332-9bbbedd596bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root          53  0.5  0.0      0     0 ?        Z    01:49   0:05 [python3] <defunct>\n",
            "root          54  0.0  0.2  54580 37408 ?        S    01:49   0:00 python3 /usr/local/bin/colab-fileshim.py\n",
            "root         103  0.7  0.9 543284 129776 ?       Sl   01:49   0:06 /usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --NotebookApp.token= --port=9000 --FileContentsManager.root_dir=/ --MappingKernelManager.root_dir=/content\n",
            "root         156  8.7 44.7 25381740 5953252 ?    Ssl  01:49   1:19 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-cfc4dfd6-c619-4205-a5fe-3bcf8fc52530.json\n",
            "root         202  0.2  0.1 539952 14072 ?        Sl   01:49   0:02 /usr/bin/python3 /usr/local/lib/python3.10/dist-packages/debugpy/adapter --for-server 48597 --host 127.0.0.1 --port 17267 --server-access-token 0b490a375833999b6e29d3282239006134046a82635f77ede94de93bceb3c847\n",
            "root        4233  0.0  0.0   6904  3140 ?        S    02:04   0:00 /bin/bash -c ps -aux | grep \"python\"\n",
            "root        4235  0.0  0.0   6444   720 ?        S    02:04   0:00 grep python\n"
          ]
        }
      ]
    }
  ]
}